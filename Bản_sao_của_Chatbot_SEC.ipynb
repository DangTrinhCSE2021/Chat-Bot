{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8c3c7da",
      "metadata": {
        "id": "e8c3c7da"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/Chatbot_SEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae56bcff",
      "metadata": {
        "id": "ae56bcff"
      },
      "source": [
        "# ðŸ’¬ðŸ¤– How to Build a Chatbot\n",
        "\n",
        "LlamaIndex serves as a bridge between your data and Language Learning Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.\n",
        "\n",
        "In this tutorial, we'll walk you through building a context-augmented chatbot using a [Data Agent](https://gpt-index.readthedocs.io/en/stable/core_modules/agent_modules/agents/root.html). This agent, powered by LLMs, is capable of intelligently executing tasks over your data. The end result is a chatbot agent equipped with a robust set of data interface tools provided by LlamaIndex to answer queries about your data.\n",
        "\n",
        "**Note**: This tutorial builds upon initial work on creating a query interface over SEC 10-K filings - [check it out here](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d).\n",
        "\n",
        "### Context\n",
        "\n",
        "In this guide, weâ€™ll build a \"10-K Chatbot\" that uses raw UBER 10-K HTML filings from Dropbox. Users can interact with the chatbot to ask questions related to the 10-K filings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "WlqJ2Hxg030a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WlqJ2Hxg030a",
        "outputId": "19d40819-680d-4346-b84e-e95ed143f6cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers\\punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping help\\tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to\n",
            "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.16.0-py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.0/1.7 MB 1.3 MB/s eta 0:00:02\n",
            "     -- ------------------------------------- 0.1/1.7 MB 1.4 MB/s eta 0:00:02\n",
            "     ------ --------------------------------- 0.3/1.7 MB 2.2 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 0.5/1.7 MB 3.0 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 1.1/1.7 MB 4.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.7/1.7 MB 6.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from unstructured) (6.1.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
            "     ------------------------------------- 981.5/981.5 kB 20.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "     ---------------------------------------- 0.0/586.9 kB ? eta -:--:--\n",
            "     ------------------------------------- 586.9/586.9 kB 36.0 MB/s eta 0:00:00\n",
            "Collecting dataclasses-json\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "     ---------------------------------------- 0.0/147.9 kB ? eta -:--:--\n",
            "     ---------------------------------------- 147.9/147.9 kB ? eta 0:00:00\n",
            "Collecting filetype\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "     ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
            "     ---------------------------------------- 64.9/64.9 kB ? eta 0:00:00\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
            "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
            "     ---- ----------------------------------- 1.6/15.8 MB 34.4 MB/s eta 0:00:01\n",
            "     ------- -------------------------------- 3.1/15.8 MB 33.1 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 4.9/15.8 MB 34.7 MB/s eta 0:00:01\n",
            "     -------------- ------------------------- 5.9/15.8 MB 37.6 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 7.1/15.8 MB 32.7 MB/s eta 0:00:01\n",
            "     --------------------- ------------------ 8.4/15.8 MB 29.9 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 8.9/15.8 MB 31.8 MB/s eta 0:00:01\n",
            "     ------------------------- ------------- 10.5/15.8 MB 29.7 MB/s eta 0:00:01\n",
            "     ------------------------- ------------- 10.5/15.8 MB 29.7 MB/s eta 0:00:01\n",
            "     ------------------------------- ------- 12.8/15.8 MB 27.3 MB/s eta 0:00:01\n",
            "     ---------------------------------- ---- 14.1/15.8 MB 26.2 MB/s eta 0:00:01\n",
            "     ------------------------------------ -- 14.9/15.8 MB 25.2 MB/s eta 0:00:01\n",
            "     --------------------------------------  15.6/15.8 MB 24.2 MB/s eta 0:00:01\n",
            "     --------------------------------------  15.8/15.8 MB 22.6 MB/s eta 0:00:01\n",
            "     --------------------------------------- 15.8/15.8 MB 17.7 MB/s eta 0:00:00\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.10.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
            "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "     ------------ --------------------------- 0.5/1.6 MB 10.5 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 1.0/1.6 MB 12.5 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 1.5/1.6 MB 10.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.6/1.6 MB 10.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (3.9.1)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
            "Collecting python-oxmsg\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Collecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting python-iso639\n",
            "  Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
            "     ---------------------------------------- 0.0/274.9 kB ? eta -:--:--\n",
            "     ------------------------------------- 274.9/274.9 kB 17.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from unstructured) (4.12.2)\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting chardet\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "     ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
            "     ------------------------------------- 199.4/199.4 kB 12.6 MB/s eta 0:00:00\n",
            "Collecting unstructured-client\n",
            "  Downloading unstructured_client-0.26.1-py3-none-any.whl (60 kB)\n",
            "     ---------------------------------------- 0.0/60.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 60.2/60.2 kB ? eta 0:00:00\n",
            "Collecting lxml\n",
            "  Downloading lxml-5.3.0-cp310-cp310-win_amd64.whl (3.8 MB)\n",
            "     ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
            "     ----- ---------------------------------- 0.5/3.8 MB 11.1 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 1.0/3.8 MB 11.0 MB/s eta 0:00:01\n",
            "     --------------- ------------------------ 1.5/3.8 MB 10.7 MB/s eta 0:00:01\n",
            "     --------------------- ------------------ 2.0/3.8 MB 10.7 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 2.5/3.8 MB 10.6 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 3.0/3.8 MB 10.7 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 3.5/3.8 MB 11.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------  3.8/3.8 MB 11.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 3.8/3.8 MB 9.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from unstructured) (4.66.5)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "     ---------------------------------------- 0.0/49.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 49.5/49.5 kB 2.6 MB/s eta 0:00:00\n",
            "Collecting typing-inspect<1,>=0.4.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: six in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (2024.9.11)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
            "Collecting olefile\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "     ---------------------------------------- 0.0/114.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 114.6/114.6 kB ? eta 0:00:00\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
            "     ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 102.2/102.2 kB ? eta 0:00:00\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "     ---------------------------------------- 0.0/167.3 kB ? eta -:--:--\n",
            "     -------------------------------------- 167.3/167.3 kB 9.8 MB/s eta 0:00:00\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "     ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 70.4/70.4 kB ? eta 0:00:00\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "     ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 126.3/126.3 kB ? eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->unstructured) (0.4.6)\n",
            "Collecting cryptography>=3.1\n",
            "  Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl (3.1 MB)\n",
            "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
            "     ------ --------------------------------- 0.5/3.1 MB 11.1 MB/s eta 0:00:01\n",
            "     ------------- -------------------------- 1.0/3.1 MB 10.7 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 1.6/3.1 MB 12.5 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 2.0/3.1 MB 11.8 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 2.5/3.1 MB 11.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  3.0/3.1 MB 11.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  3.1/3.1 MB 10.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 3.1/3.1 MB 9.3 MB/s eta 0:00:00\n",
            "Collecting pydantic<2.10.0,>=2.9.0\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "     ---------------------------------------- 0.0/434.9 kB ? eta -:--:--\n",
            "     ------------------------------------- 434.9/434.9 kB 13.3 MB/s eta 0:00:00\n",
            "Collecting python-dateutil==2.8.2\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "     ---------------------------------------- 0.0/247.7 kB ? eta -:--:--\n",
            "     ------------------------------------- 247.7/247.7 kB 14.8 MB/s eta 0:00:00\n",
            "Collecting httpx>=0.27.0\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "     ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 76.4/76.4 kB ? eta 0:00:00\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Collecting jsonpath-python<2.0.0,>=1.0.6\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting eval-type-backport<0.3.0,>=0.2.0\n",
            "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting pypdf>=4.0\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "     ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
            "     ------------------------------------- 294.5/294.5 kB 17.8 MB/s eta 0:00:00\n",
            "Collecting requests-toolbelt>=1.0.0\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "     ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
            "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
            "     ------------------------------------- 181.3/181.3 kB 10.7 MB/s eta 0:00:00\n",
            "Collecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 0.0/78.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 78.0/78.0 kB ? eta 0:00:00\n",
            "Collecting anyio\n",
            "  Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
            "     ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 90.4/90.4 kB ? eta 0:00:00\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting h11<0.15,>=0.13\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.1)\n",
            "Collecting pydantic-core==2.23.4\n",
            "  Downloading pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
            "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "     ---------- ----------------------------- 0.5/1.9 MB 31.4 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 1.0/1.9 MB 15.9 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 1.5/1.9 MB 13.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.9/1.9 MB 12.2 MB/s eta 0:00:00\n",
            "Collecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "     ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
            "     -------------------------------------- 117.6/117.6 kB 6.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Installing collected packages: filetype, wrapt, urllib3, tabulate, soupsieve, sniffio, rapidfuzz, python-magic, python-iso639, python-dateutil, pypdf, pydantic-core, pycparser, olefile, numpy, mypy-extensions, marshmallow, lxml, langdetect, jsonpath-python, idna, h11, eval-type-backport, emoji, charset-normalizer, chardet, certifi, backoff, annotated-types, typing-inspect, requests, python-oxmsg, pydantic, httpcore, cffi, beautifulsoup4, anyio, requests-toolbelt, httpx, dataclasses-json, cryptography, unstructured-client, unstructured\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Running setup.py install for langdetect: started\n",
            "  Running setup.py install for langdetect: finished with status 'done'\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 backoff-2.2.1 beautifulsoup4-4.12.3 certifi-2024.8.30 cffi-1.17.1 chardet-5.2.0 charset-normalizer-3.4.0 cryptography-43.0.3 dataclasses-json-0.6.7 emoji-2.14.0 eval-type-backport-0.2.0 filetype-1.2.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 idna-3.10 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.3.0 marshmallow-3.23.0 mypy-extensions-1.0.0 numpy-1.26.4 olefile-0.47 pycparser-2.22 pydantic-2.9.2 pydantic-core-2.23.4 pypdf-5.0.1 python-dateutil-2.8.2 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.0 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 soupsieve-2.6 tabulate-0.9.0 typing-inspect-0.9.0 unstructured-0.16.0 unstructured-client-0.26.1 urllib3-2.2.3 wrapt-1.16.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: langdetect is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('all')\n",
        "%pip install -U unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f3e1de",
      "metadata": {
        "id": "03f3e1de"
      },
      "source": [
        "### Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "35c20fbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "35c20fbe",
        "outputId": "94ce71c3-3b14-445c-b454-84d4c3e85e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-readers-file\n",
            "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.0\n",
            "  Downloading llama_index_core-0.11.19-py3-none-any.whl (1.6 MB)\n",
            "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.1/1.6 MB 2.3 MB/s eta 0:00:01\n",
            "     ------ --------------------------------- 0.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
            "     --------------- ------------------------ 0.6/1.6 MB 4.8 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 1.4/1.6 MB 8.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.6/1.6 MB 8.4 MB/s eta 0:00:00\n",
            "Collecting pypdf<5.0.0,>=4.0.1\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "     ---------------------------------------- 0.0/295.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 295.8/295.8 kB ? eta 0:00:00\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-readers-file) (4.12.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
            "     ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
            "     ----- ---------------------------------- 1.6/11.6 MB 34.4 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 3.2/11.6 MB 41.0 MB/s eta 0:00:01\n",
            "     ---------------- ----------------------- 4.9/11.6 MB 39.2 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 5.4/11.6 MB 38.3 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 5.4/11.6 MB 38.3 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 7.0/11.6 MB 26.3 MB/s eta 0:00:01\n",
            "     ---------------------------------- ---- 10.3/11.6 MB 32.7 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 10.5/11.6 MB 31.1 MB/s eta 0:00:01\n",
            "     --------------------------------------  11.6/11.6 MB 28.5 MB/s eta 0:00:01\n",
            "     --------------------------------------- 11.6/11.6 MB 24.2 MB/s eta 0:00:00\n",
            "Collecting striprtf<0.0.27,>=0.0.26\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "     ---------------------------------------- 0.0/179.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 179.6/179.6 kB ? eta 0:00:00\n",
            "Collecting deprecated>=1.2.9.3\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.6\n",
            "  Downloading aiohttp-3.10.10-cp310-cp310-win_amd64.whl (381 kB)\n",
            "     ---------------------------------------- 0.0/381.1 kB ? eta -:--:--\n",
            "     ------------------------------------- 381.1/381.1 kB 24.7 MB/s eta 0:00:00\n",
            "Collecting pillow>=9.0.0\n",
            "  Downloading pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
            "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "     ---------------------------- ----------- 1.8/2.6 MB 38.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.6/2.6 MB 32.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.16.0)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.6.0)\n",
            "Collecting tiktoken>=0.3.3\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
            "     ---------------------------------------- 0.0/884.2 kB ? eta -:--:--\n",
            "     ------------------------------------- 884.2/884.2 kB 58.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: httpx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.27.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.66.5)\n",
            "Collecting networkx>=3.0\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "     -------------------------------------- - 1.6/1.7 MB 52.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.7/1.7 MB 36.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.32.3)\n",
            "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
            "  Downloading SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl (2.1 MB)\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     -------------- ------------------------- 0.8/2.1 MB 24.8 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 1.8/2.1 MB 23.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.1/2.1 MB 19.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.9.2)\n",
            "Collecting PyYAML>=6.0.1\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
            "     ---------------------------------------- 0.0/161.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 161.8/161.8 kB ? eta 0:00:00\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.9.1)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.26.4)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.6.7)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "     ---------------------------------------- 0.0/508.0 kB ? eta -:--:--\n",
            "     ------------------------------------- 508.0/508.0 kB 31.1 MB/s eta 0:00:00\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "     ---------------------------------------- 0.0/346.6 kB ? eta -:--:--\n",
            "     ---------------------------- -------- 266.2/346.6 kB 16.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- 346.6/346.6 kB 10.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama-index-readers-file) (2.8.2)\n",
            "Collecting yarl<2.0,>=1.12.0\n",
            "  Downloading yarl-1.16.0-cp310-cp310-win_amd64.whl (89 kB)\n",
            "     ---------------------------------------- 0.0/89.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 89.2/89.2 kB ? eta 0:00:00\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
            "     ---------------------------------------- 0.0/50.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 50.4/50.4 kB ? eta 0:00:00\n",
            "Collecting async-timeout<5.0,>=4.0\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "     ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 63.0/63.0 kB ? eta 0:00:00\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.9.11)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.1.7)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.23.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.8.30)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
            "     ---------------------------------------- 0.0/298.4 kB ? eta -:--:--\n",
            "     ------------------------------------- 298.4/298.4 kB 19.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.6.2.post1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (24.1)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.2.0-cp310-cp310-win_amd64.whl (44 kB)\n",
            "     ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.2)\n",
            "Installing collected packages: striprtf, pytz, dirtyjson, tzdata, tenacity, PyYAML, pypdf, propcache, pillow, networkx, multidict, greenlet, fsspec, frozenlist, deprecated, attrs, async-timeout, aiohappyeyeballs, yarl, tiktoken, SQLAlchemy, pandas, aiosignal, aiohttp, llama-index-core, llama-index-readers-file\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 5.0.1\n",
            "    Uninstalling pypdf-5.0.1:\n",
            "      Successfully uninstalled pypdf-5.0.1\n",
            "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 deprecated-1.2.14 dirtyjson-1.0.8 frozenlist-1.4.1 fsspec-2024.10.0 greenlet-3.1.1 llama-index-core-0.11.19 llama-index-readers-file-0.2.2 multidict-6.1.0 networkx-3.4.2 pandas-2.2.3 pillow-11.0.0 propcache-0.2.0 pypdf-4.3.1 pytz-2024.2 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.8.0 tzdata-2024.2 yarl-1.16.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-embeddings-openai\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-embeddings-openai) (0.11.19)\n",
            "Collecting openai>=1.1.0\n",
            "  Downloading openai-1.52.1-py3-none-any.whl (386 kB)\n",
            "     ---------------------------------------- 0.0/386.9 kB ? eta -:--:--\n",
            "     --- --------------------------------- 41.0/386.9 kB 991.0 kB/s eta 0:00:01\n",
            "     ----------------- -------------------- 174.1/386.9 kB 2.1 MB/s eta 0:00:01\n",
            "     -------------------------------------  378.9/386.9 kB 2.9 MB/s eta 0:00:01\n",
            "     -------------------------------------- 386.9/386.9 kB 2.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.10.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.9.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.66.5)\n",
            "Requirement already satisfied: httpx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.27.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.6.7)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.5.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (11.0.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.36)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.26.4)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.8.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.6.2.post1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Collecting distro<2,>=1.7.0\n",
            "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Collecting jiter<1,>=0.4.0\n",
            "  Downloading jiter-0.6.1-cp310-none-win_amd64.whl (200 kB)\n",
            "     ---------------------------------------- 0.0/200.0 kB ? eta -:--:--\n",
            "     ------------------------------------- 200.0/200.0 kB 12.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.9.11)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.23.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.23.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.2.0)\n",
            "Installing collected packages: jiter, distro, openai, llama-index-embeddings-openai\n",
            "Successfully installed distro-1.9.0 jiter-0.6.1 llama-index-embeddings-openai-0.2.5 openai-1.52.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-agent-openai\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: openai>=1.14.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-agent-openai) (1.52.1)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-agent-openai) (0.11.19)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.9\n",
            "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (4.66.5)\n",
            "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (4.12.2)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.0.8)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.9.0)\n",
            "Requirement already satisfied: httpx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.27.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2024.10.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2.0.36)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.26.4)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.6.7)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (3.4.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.6.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2.32.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2.9.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (3.10.10)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.2.14)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (11.0.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (3.9.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai) (1.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai) (1.9.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (6.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (24.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2.4.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.0.6)\n",
            "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2024.8.30)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.14.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2024.9.11)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.4.2)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (8.1.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2.23.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (3.23.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-agent-openai) (0.2.0)\n",
            "Installing collected packages: llama-index-llms-openai, llama-index-agent-openai\n",
            "Successfully installed llama-index-agent-openai-0.3.4 llama-index-llms-openai-0.2.16\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-openai in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.16)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-llms-openai) (1.52.1)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-llms-openai) (0.11.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.10.0)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.2.14)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.10.10)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: httpx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.27.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.66.5)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.8.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.32.3)\n",
            "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (11.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.6.2.post1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (6.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.4.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.6)\n",
            "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.8.30)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.14.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2024.9.11)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.23.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (3.23.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.7->llama-index-llms-openai) (0.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-readers-file\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-agent-openai\n",
        "%pip install llama-index-llms-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1211059f",
      "metadata": {
        "id": "1211059f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "CuHeyb224pI2",
      "metadata": {
        "id": "CuHeyb224pI2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de6f5b40, raw_cell=\"# set text wrapping\n",
            "from IPython.display import HT..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#W6sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# set text wrapping\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "def set_css(*args, **kwargs):\n",
        "    display(\n",
        "        HTML(\n",
        "            \"\"\"\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  \"\"\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "get_ipython().events.register(\"pre_run_cell\", set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218cc812",
      "metadata": {
        "id": "218cc812"
      },
      "source": [
        "### Ingest Data\n",
        "\n",
        "Let's first download the raw 10-k files, from 2019-2022."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YC4R6nkCp91d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "YC4R6nkCp91d",
        "outputId": "2a1f76b3-3b6f-4fbd-8387-904428a98a6f"
      },
      "outputs": [],
      "source": [
        "# NOTE: the code examples assume you're operating within a Jupyter notebook.\n",
        "# download files\n",
        "!mkdir data\n",
        "!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\n",
        "!unzip data/UBER.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2200f83",
      "metadata": {
        "id": "a2200f83"
      },
      "source": [
        "To parse the HTML files into formatted text, we use the [Unstructured](https://github.com/Unstructured-IO/unstructured) library. Thanks to [LlamaHub](https://llamahub.ai/), we can directly integrate with Unstructured, allowing conversion of any text into a Document format that LlamaIndex can ingest.\n",
        "\n",
        "First we install the necessary packages:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f55a00d7",
      "metadata": {
        "id": "f55a00d7"
      },
      "source": [
        "Then we can use the `UnstructuredReader` to parse the HTML files into a list of `Document` objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5dcd0f94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5dcd0f94",
        "outputId": "c15ad085-aed4-4084-c12f-e86c08e09646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2b44c34f0, raw_cell=\"from llama_index.readers.file import UnstructuredR..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X14sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "from llama_index.readers.file import UnstructuredReader\n",
        "from pathlib import Path\n",
        "\n",
        "years = [2022, 2021, 2020, 2019]\n",
        "\n",
        "loader = UnstructuredReader()\n",
        "doc_set = {}\n",
        "all_docs = []\n",
        "for year in years:\n",
        "    year_docs = loader.load_data(\n",
        "        file=Path(f\"./data/UBER/UBER_{year}.html\"), split_documents=False\n",
        "    )\n",
        "    # insert year metadata into each year\n",
        "    for d in year_docs:\n",
        "        d.metadata = {\"year\": year}\n",
        "    doc_set[year] = year_docs\n",
        "    all_docs.extend(year_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "312d0cfe",
      "metadata": {
        "id": "312d0cfe"
      },
      "source": [
        "### Setting up Vector Indices for each year\n",
        "\n",
        "We first setup a vector index for each year. Each vector index allows us\n",
        "to ask questions about the 10-K filing of a given year.\n",
        "\n",
        "We build each index and save it to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7bw0fOMcJ6JZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bw0fOMcJ6JZ",
        "outputId": "2c64312a-2cde-4cfc-8811-67759dad53c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2b44ffa30, raw_cell=\"%pip install --upgrade llama_index\n",
            "\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X16sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.11.19-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.0/1.2 MB 660.6 kB/s eta 0:00:02\n",
            "     --- ------------------------------------ 0.1/1.2 MB 1.2 MB/s eta 0:00:01\n",
            "     ------ --------------------------------- 0.2/1.2 MB 1.3 MB/s eta 0:00:01\n",
            "     --------- ------------------------------ 0.3/1.2 MB 1.8 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 0.6/1.2 MB 2.8 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 0.7/1.2 MB 2.4 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 1.0/1.2 MB 3.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.2/1.2 MB 3.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.3.4)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (3.9.1)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.2.5)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.2.2)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.19 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.11.19)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama_index) (0.2.16)\n",
            "Requirement already satisfied: openai>=1.14.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.52.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (4.12.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (0.6.7)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2.0.36)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.2.14)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (11.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2.9.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.6.0)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.0.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.26.4)\n",
            "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2024.10.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (6.0.2)\n",
            "Requirement already satisfied: httpx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (0.27.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2.32.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (4.66.5)\n",
            "Collecting llama-cloud>=0.0.11\n",
            "  Downloading llama_cloud-0.1.4-py3-none-any.whl (176 kB)\n",
            "     ---------------------------------------- 0.0/176.8 kB ? eta -:--:--\n",
            "     ------------------------------------- 176.8/176.8 kB 10.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.3.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.12.3)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (0.0.26)\n",
            "Collecting llama-parse>=0.5.0\n",
            "  Downloading llama_parse-0.5.11-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.9.11)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.4.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (4.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.4.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (24.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (6.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (2.6)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.0.6)\n",
            "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (2024.8.30)\n",
            "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.3.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (4.6.2.post1)\n",
            "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.14.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk>3.8.1->llama_index) (0.4.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.19->llama_index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.2.0)\n",
            "Installing collected packages: llama-cloud, llama-index-legacy, llama-parse, llama-index-indices-managed-llama-cloud, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "Successfully installed llama-cloud-0.1.4 llama-index-cli-0.3.1 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.11 llama_index-0.11.19\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade llama_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7c90fafc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7c90fafc",
        "outputId": "0451c3b8-4cda-4f5f-ef62-c0bf7cc819f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2b44c3070, raw_cell=\"# initialize simple vector indices\n",
            "# NOTE: don't r..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X20sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "# initialize simple vector indices\n",
        "# NOTE: don't run this cell if the indices are already loaded!\n",
        "from llama_index.core import VectorStoreIndex, StorageContext\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 64\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "\n",
        "index_set = {}\n",
        "for year in years:\n",
        "    storage_context = StorageContext.from_defaults()\n",
        "    cur_index = VectorStoreIndex.from_documents(\n",
        "        doc_set[year],\n",
        "        storage_context=storage_context,\n",
        "    )\n",
        "    index_set[year] = cur_index\n",
        "    storage_context.persist(persist_dir=f\"./storage/{year}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0704f6b",
      "metadata": {
        "id": "f0704f6b"
      },
      "source": [
        "To load an index from disk, do the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7100e1b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7100e1b5",
        "outputId": "c2274479-e752-4db5-a716-6e246bb94c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2e5d32500, raw_cell=\"# Load indices from disk\n",
            "from llama_index.core imp..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X22sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "# Load indices from disk\n",
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "index_set = {}\n",
        "for year in years:\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "        persist_dir=f\"./storage/{year}\"\n",
        "    )\n",
        "    cur_index = load_index_from_storage(\n",
        "        storage_context,\n",
        "    )\n",
        "    index_set[year] = cur_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa3f903",
      "metadata": {
        "id": "0aa3f903"
      },
      "source": [
        "### Setting up a Sub Question Query Engine to Synthesize Answers Across 10-K Filings\n",
        "\n",
        "Since we have access to documents of 4 years, we may not only want to ask questions regarding the 10-K document of a given year, but ask questions that require analysis over all 10-K filings.\n",
        "\n",
        "To address this, we can use a [Sub Question Query Engine](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/sub_question_query_engine.html). It decomposes a query into subqueries, each answered by an individual vector index, and synthesizes the results to answer the overall query.\n",
        "\n",
        "LlamaIndex provides some wrappers around indices (and query engines) so that they can be used by query engines and agents. First we define a `QueryEngineTool` for each vector index.\n",
        "Each tool has a name and a description; these are what the LLM agent sees to decide which tool to choose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ce53419f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ce53419f",
        "outputId": "6d52abd4-7ab7-4af5-8a68-95c1d791a1c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2e5d33d00, raw_cell=\"from llama_index.core.tools import QueryEngineTool..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X24sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "individual_query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=index_set[year].as_query_engine(),\n",
        "        metadata=ToolMetadata(\n",
        "            name=f\"vector_index_{year}\",\n",
        "            description=(\n",
        "                \"useful for when you want to answer queries about the\"\n",
        "                f\" {year} SEC 10-K for Uber\"\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        "    for year in years\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8d2177",
      "metadata": {
        "id": "6e8d2177"
      },
      "source": [
        "Now we can create the Sub Question Query Engine, which will allow us to synthesize answers across the 10-K filings. We pass in the `individual_query_engine_tools` we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9c6cee32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9c6cee32",
        "outputId": "9beb5219-a530-4869-e2db-fa7526306f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2e5d335e0, raw_cell=\"from llama_index.core.query_engine import SubQuest..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X26sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    query_engine_tools=individual_query_engine_tools,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de5362b6",
      "metadata": {
        "id": "de5362b6"
      },
      "source": [
        "### Setting up the Chatbot Agent\n",
        "\n",
        "We use a LlamaIndex Data Agent to setup the outer chatbot agent, which has access to a set of Tools. Specifically, we will use an OpenAIAgent, that takes advantage of OpenAI API function calling. We want to use the separate Tools we defined previously for each index (corresponding to a given year), as well as a tool for the sub question query engine we defined above.\n",
        "\n",
        "First we define a `QueryEngineTool` for the sub question query engine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f42e5a52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f42e5a52",
        "outputId": "6c4925a0-08a3-4a54-e6dd-bf6f2e3b5f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de7725f0, raw_cell=\"query_engine_tool = QueryEngineTool(\n",
            "    query_eng..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X31sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query_engine_tool = QueryEngineTool(\n",
        "    query_engine=query_engine,\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"sub_question_query_engine\",\n",
        "        description=(\n",
        "            \"useful for when you want to answer queries that require analyzing\"\n",
        "            \" multiple SEC 10-K documents for Uber\"\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdcc922d",
      "metadata": {
        "id": "fdcc922d"
      },
      "source": [
        "Then, we combine the Tools we defined above into a single list of tools for the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fad25dca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fad25dca",
        "outputId": "56f742a4-e200-4573-e9d1-43e2c16abc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de6fe260, raw_cell=\"tools = individual_query_engine_tools + [query_eng..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X33sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tools = individual_query_engine_tools + [query_engine_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14219225",
      "metadata": {
        "id": "14219225"
      },
      "source": [
        "Finally, we call `OpenAIAgent.from_tools` to create the agent, passing in the list of tools we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bb01833c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bb01833c",
        "outputId": "99530be4-e1ee-465e-b69a-05b3755db8ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de6f4970, raw_cell=\"from llama_index.agent.openai import OpenAIAgent\n",
            "\n",
            "..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X35sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "\n",
        "agent = OpenAIAgent.from_tools(tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e6112d4",
      "metadata": {
        "id": "9e6112d4"
      },
      "source": [
        "### Testing the Agent\n",
        "\n",
        "We can now test the agent with various queries.\n",
        "\n",
        "If we test it with a simple \"hello\" query, the agent does not use any Tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "269e6700",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "269e6700",
        "outputId": "640b3f96-7584-4c48-d7ae-9bdea5fe8ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de6fd1e0, raw_cell=\"response = agent.chat(\"hi, i am bob\")\n",
            "print(str(re..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X40sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: hi, i am bob\n",
            "Hello Bob! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"hi, i am bob\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe5fb92",
      "metadata": {
        "id": "2fe5fb92"
      },
      "source": [
        "If we test it with a query regarding the 10-k of a given year, the agent will use\n",
        "the relevant vector index Tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bb8226e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "bb8226e6",
        "outputId": "d8753406-f585-4423-809f-4b6eb23a0c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de773250, raw_cell=\"response = agent.chat(\n",
            "    \"What were some of the ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X42sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What were some of the biggest risk factors in 2020 for Uber?\n",
            "=== Calling Function ===\n",
            "Calling function: vector_index_2020 with args: {\"input\":\"biggest risk factors\"}\n",
            "Got output: The biggest risk factors include the adverse effects of the COVID-19 pandemic on the business, potential reclassification of Drivers, intense competition in the industries, significant losses and uncertain path to profitability, challenges in maintaining a critical mass of platform users, operational and cultural challenges, negative impact on brand reputation, difficulties in managing growth, potential safety incidents, financial impacts of fines or enforcement measures, and the ongoing uncertainty and potential long-term effects of the pandemic on business operations and financial results.\n",
            "========================\n",
            "\n",
            "In 2020, some of the biggest risk factors for Uber included the adverse effects of the COVID-19 pandemic on the business, potential reclassification of Drivers, intense competition in the industries, significant losses and uncertain path to profitability, challenges in maintaining a critical mass of platform users, operational and cultural challenges, negative impact on brand reputation, difficulties in managing growth, potential safety incidents, financial impacts of fines or enforcement measures, and the ongoing uncertainty and potential long-term effects of the pandemic on business operations and financial results.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\n",
        "    \"What were some of the biggest risk factors in 2020 for Uber?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ac181f",
      "metadata": {
        "id": "78ac181f"
      },
      "source": [
        "Finally, if we test it with a query to compare/contrast risk factors across years, the agent will use the Sub Question Query Engine Tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "72e475bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "72e475bf",
        "outputId": "ba6366c1-ad7b-42c9-f16d-9c728a0792dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2de6fdc30, raw_cell=\"cross_query_str = (\n",
            "    \"Compare/contrast the risk..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X44sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Compare/contrast the risk factors described in the Uber 10-K across years. Give answer in bullet points.\n",
            "=== Calling Function ===\n",
            "Calling function: sub_question_query_engine with args: {\"input\":\"compare risk factors\"}\n",
            "Generated 4 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[vector_index_2022] Q: What are the risk factors mentioned in the 2022 SEC 10-K for Uber?\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[vector_index_2021] Q: What are the risk factors mentioned in the 2021 SEC 10-K for Uber?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[vector_index_2020] Q: What are the risk factors mentioned in the 2020 SEC 10-K for Uber?\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m[vector_index_2019] Q: What are the risk factors mentioned in the 2019 SEC 10-K for Uber?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[vector_index_2020] A: Legal and regulatory risks, risks related to data processing, risks related to intellectual property protection, volatility in stock price, general economic risks including the impact of the COVID-19 pandemic on business operations and financial condition.\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[vector_index_2022] A: If Uber is unable to attract or maintain a critical mass of Drivers, consumers, merchants, shippers, and carriers, whether due to competition or other factors, their platform will become less appealing to users, potentially leading to adverse financial impacts.\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[vector_index_2021] A: If Uber is unable to attract or maintain a critical mass of Drivers, consumers, merchants, shippers, and carriers, whether due to competition or other factors, their platform may become less appealing to users, which could adversely impact their financial results.\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m[vector_index_2019] A: The risk factors mentioned in the 2019 SEC 10-K for Uber include legal proceedings, litigation, claims, and government investigations, particularly related to the classification of Drivers and compliance with applicable laws. The company also highlights the potential burden on management and employees, as well as the costly defense costs associated with such legal matters. Additionally, Uber acknowledges the risk of unfavorable preliminary and interim rulings in these legal proceedings.\n",
            "\u001b[0mGot output: The risk factors mentioned in the 2022, 2021, and 2020 SEC 10-K filings for Uber primarily focus on the company's ability to attract and retain a critical mass of users and the potential financial impacts if this critical mass is not maintained. In addition, the 2020 SEC 10-K also highlights legal and regulatory risks, data processing risks, intellectual property protection risks, stock price volatility, and general economic risks including those related to the COVID-19 pandemic. The 2019 SEC 10-K emphasizes legal proceedings, litigation, claims, and government investigations, particularly concerning the classification of Drivers and compliance with laws, as well as the associated management burden and defense costs.\n",
            "========================\n",
            "\n",
            "Here is a comparison of the risk factors described in the Uber 10-K filings across different years:\n",
            "\n",
            "2022:\n",
            "- Focus on attracting and retaining a critical mass of users\n",
            "- Potential financial impacts if critical mass is not maintained\n",
            "\n",
            "2021:\n",
            "- Similar focus on attracting and retaining users\n",
            "- Legal and regulatory risks\n",
            "- Data processing risks\n",
            "- Intellectual property protection risks\n",
            "- Stock price volatility\n",
            "- General economic risks, including those related to the COVID-19 pandemic\n",
            "\n",
            "2020:\n",
            "- Emphasis on legal and regulatory risks\n",
            "- Data processing risks\n",
            "- Intellectual property protection risks\n",
            "- Stock price volatility\n",
            "- General economic risks, including those related to the COVID-19 pandemic\n",
            "\n",
            "2019:\n",
            "- Legal proceedings, litigation, claims, and government investigations\n",
            "- Concerns about the classification of Drivers and compliance with laws\n",
            "- Management burden and defense costs associated with legal issues\n",
            "\n",
            "These bullet points highlight the evolution and consistency of risk factors identified in Uber's SEC 10-K filings over the years.\n"
          ]
        }
      ],
      "source": [
        "cross_query_str = (\n",
        "    \"Compare/contrast the risk factors described in the Uber 10-K across\"\n",
        "    \" years. Give answer in bullet points.\"\n",
        ")\n",
        "\n",
        "response = agent.chat(cross_query_str)\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1153ee23",
      "metadata": {
        "id": "1153ee23"
      },
      "source": [
        "### Setting up the Chatbot Loop\n",
        "\n",
        "Now that we have the chatbot setup, it only takes a few more steps to setup a basic interactive loop to chat with our SEC-augmented chatbot!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa14fa6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "5fa14fa6",
        "outputId": "d2e908b5-beed-4803-e538-e0fffd390f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000001C2B44DC5E0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1c2ee86b700, raw_cell=\"agent = OpenAIAgent.from_tools(tools)  # verbose=F..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VGU/Year_4/Elective_2_Vinh/Chat_bot/B%E1%BA%A3n_sao_c%E1%BB%A7a_Chatbot_SEC.ipynb#X46sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "agent = OpenAIAgent.from_tools(tools)  # verbose=False by default\n",
        "\n",
        "while True:\n",
        "    text_input = input(\"User: \")\n",
        "    if text_input == \"exit\":\n",
        "        break\n",
        "    response = agent.chat(text_input)\n",
        "    print(f\"Agent: {response}\")\n",
        "\n",
        "# User: What were some of the legal proceedings against Uber in 2022?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
